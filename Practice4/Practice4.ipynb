{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqJgx9_RdEhP",
        "outputId": "7558338e-79bb-4830-b342-a1932e03ceb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting gpu_memory_optimization.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile gpu_memory_optimization.cu\n",
        "\n",
        "#include <cuda_runtime.h>              // Основные функции CUDA\n",
        "#include <device_launch_parameters.h>  // Параметры запуска kernel\n",
        "\n",
        "#include <iostream>    // Ввод-вывод\n",
        "#include <vector>      // Контейнер vector\n",
        "#include <random>      // Генерация случайных чисел\n",
        "\n",
        "#define THREADS 256     // Количество потоков в одном CUDA-блоке\n",
        "\n",
        "// =====================================================\n",
        "// Генерация массива случайных чисел (на CPU)\n",
        "// Используется для подготовки входных данных\n",
        "// =====================================================\n",
        "void generateArray(std::vector<int>& a) {\n",
        "    std::mt19937 gen(42);                          // Фиксированный seed\n",
        "    std::uniform_int_distribution<> dist(0, 100); // Диапазон значений\n",
        "    for (auto& x : a)\n",
        "        x = dist(gen);\n",
        "}\n",
        "\n",
        "// =====================================================\n",
        "// REDUCTION 1: ТОЛЬКО ГЛОБАЛЬНАЯ ПАМЯТЬ\n",
        "// Каждый поток добавляет свой элемент через atomicAdd\n",
        "// =====================================================\n",
        "__global__ void reductionGlobal(int* data, int* result, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Проверка выхода за границы массива\n",
        "    if (idx < n) {\n",
        "        // Атомарное сложение в глобальной памяти\n",
        "        atomicAdd(result, data[idx]);\n",
        "    }\n",
        "}\n",
        "\n",
        "// =====================================================\n",
        "// REDUCTION 2: ГЛОБАЛЬНАЯ + РАЗДЕЛЯЕМАЯ ПАМЯТЬ\n",
        "// Редукция сначала выполняется внутри блока\n",
        "// =====================================================\n",
        "__global__ void reductionShared(int* data, int* result, int n) {\n",
        "    // Разделяемая память для текущего блока\n",
        "    __shared__ int sdata[THREADS];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * blockDim.x + tid;\n",
        "\n",
        "    // Загрузка данных из глобальной памяти в shared memory\n",
        "    sdata[tid] = (idx < n) ? data[idx] : 0;\n",
        "    __syncthreads();\n",
        "\n",
        "    // Параллельная редукция внутри блока\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride)\n",
        "            sdata[tid] += sdata[tid + stride];\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Запись частичной суммы блока в глобальную память\n",
        "    if (tid == 0)\n",
        "        atomicAdd(result, sdata[0]);\n",
        "}\n",
        "\n",
        "// =====================================================\n",
        "// BUBBLE SORT ДЛЯ ПОДМАССИВОВ\n",
        "// Используются локальные переменные потоков\n",
        "// =====================================================\n",
        "__global__ void bubbleSubarray(int* data, int chunk) {\n",
        "    // Начальный индекс подмассива для данного блока\n",
        "    int start = blockIdx.x * chunk;\n",
        "\n",
        "    // Классическая сортировка пузырьком\n",
        "    for (int i = 0; i < chunk; i++) {\n",
        "        for (int j = start; j < start + chunk - 1; j++) {\n",
        "            int a = data[j];\n",
        "            int b = data[j + 1];\n",
        "\n",
        "            if (a > b) {\n",
        "                data[j]     = b;\n",
        "                data[j + 1] = a;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// =====================================================\n",
        "// СЛИЯНИЕ ОТСОРТИРОВАННЫХ ПОДМАССИВОВ\n",
        "// Используется разделяемая память\n",
        "// =====================================================\n",
        "__global__ void mergeShared(int* input, int* output, int width, int n) {\n",
        "    // Динамически выделяемая shared memory\n",
        "    extern __shared__ int s[];\n",
        "\n",
        "    int tid   = threadIdx.x;\n",
        "    int block = blockIdx.x;\n",
        "\n",
        "    // Границы подмассивов\n",
        "    int left  = block * 2 * width;\n",
        "    int mid   = min(left + width, n);\n",
        "    int right = min(left + 2 * width, n);\n",
        "\n",
        "    // Загрузка данных в shared memory\n",
        "    for (int i = left + tid; i < right; i += blockDim.x)\n",
        "        s[i - left] = input[i];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    int i = 0;               // Левый подмассив\n",
        "    int j = mid - left;      // Правый подмассив\n",
        "    int k = left;            // Индекс записи результата\n",
        "\n",
        "    // Слияние двух отсортированных подмассивов\n",
        "    while (i < mid - left && j < right - left)\n",
        "        output[k++] = (s[i] < s[j]) ? s[i++] : s[j++];\n",
        "\n",
        "    // Копирование оставшихся элементов\n",
        "    while (i < mid - left)   output[k++] = s[i++];\n",
        "    while (j < right - left) output[k++] = s[j++];\n",
        "}\n",
        "\n",
        "// =====================================================\n",
        "// MAIN\n",
        "// =====================================================\n",
        "int main() {\n",
        "    // Размеры массивов для тестирования\n",
        "    std::vector<int> sizes = {10000, 100000, 1000000};\n",
        "\n",
        "    for (int n : sizes) {\n",
        "        std::cout << \"\\nРазмер массива: \" << n << std::endl;\n",
        "\n",
        "        // ---------------- Подготовка данных ----------------\n",
        "        std::vector<int> h_data(n);\n",
        "        generateArray(h_data);\n",
        "\n",
        "        int* d_data;\n",
        "        cudaMalloc(&d_data, n * sizeof(int));\n",
        "        cudaMemcpy(d_data, h_data.data(),\n",
        "                   n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "        // ================= REDUCTION =================\n",
        "        int* d_sum;\n",
        "        cudaMalloc(&d_sum, sizeof(int));\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        // ---- Редукция: только глобальная память ----\n",
        "        cudaMemset(d_sum, 0, sizeof(int));\n",
        "        cudaEventRecord(start);\n",
        "        reductionGlobal<<<(n + THREADS - 1) / THREADS, THREADS>>>(d_data, d_sum, n);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        float tGlobal;\n",
        "        cudaEventElapsedTime(&tGlobal, start, stop);\n",
        "        std::cout << \"Reduction (global): \" << tGlobal << \" ms\\n\";\n",
        "\n",
        "        // ---- Редукция: глобальная + разделяемая память ----\n",
        "        cudaMemset(d_sum, 0, sizeof(int));\n",
        "        cudaEventRecord(start);\n",
        "        reductionShared<<<(n + THREADS - 1) / THREADS, THREADS>>>(d_data, d_sum, n);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        float tShared;\n",
        "        cudaEventElapsedTime(&tShared, start, stop);\n",
        "        std::cout << \"Reduction (shared): \" << tShared << \" ms\\n\";\n",
        "\n",
        "        // ================= SORT =================\n",
        "        int chunk  = 256;          // Размер подмассива\n",
        "        int blocks = n / chunk;    // Количество блоков\n",
        "\n",
        "        int* d_temp;\n",
        "        cudaMalloc(&d_temp, n * sizeof(int));\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "\n",
        "        // Сортировка подмассивов пузырьком\n",
        "        bubbleSubarray<<<blocks, 1>>>(d_data, chunk);\n",
        "\n",
        "        // Поэтапное слияние подмассивов\n",
        "        for (int w = chunk; w < n; w *= 2) {\n",
        "            mergeShared<<<(n + 2*w - 1) / (2*w),\n",
        "                           THREADS,\n",
        "                           2*w * sizeof(int)>>>(d_data, d_temp, w, n);\n",
        "            std::swap(d_data, d_temp);\n",
        "        }\n",
        "\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        float tSort;\n",
        "        cudaEventElapsedTime(&tSort, start, stop);\n",
        "        std::cout << \"Sort (optimized): \" << tSort << \" ms\\n\";\n",
        "\n",
        "        // Освобождение памяти GPU\n",
        "        cudaFree(d_data);\n",
        "        cudaFree(d_temp);\n",
        "        cudaFree(d_sum);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc gpu_memory_optimization.cu -o gpu_mem\n",
        "!./gpu_mem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxNQAutOeHIr",
        "outputId": "23e0155e-8a4b-4ab8-91be-535406aeff7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Размер массива: 10000\n",
            "Reduction (global): 7.43219 ms\n",
            "Reduction (shared): 0.004224 ms\n",
            "Sort (optimized): 0.006144 ms\n",
            "\n",
            "Размер массива: 100000\n",
            "Reduction (global): 0.002048 ms\n",
            "Reduction (shared): 0.002624 ms\n",
            "Sort (optimized): 0.004992 ms\n",
            "\n",
            "Размер массива: 1000000\n",
            "Reduction (global): 0.007296 ms\n",
            "Reduction (shared): 0.002688 ms\n",
            "Sort (optimized): 0.006144 ms\n"
          ]
        }
      ]
    }
  ]
}