# Assignment 3

### 1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?

В архитектуре CUDA используются регистры, разделяемая память, глобальная, локальная, константная и текстурная память.
Самыми быстрыми являются регистры, так как они расположены непосредственно в вычислительных ядрах. Разделяемая память также имеет низкую задержку доступа и используется внутри блока потоков. Глобальная память обладает наибольшей задержкой, но доступна всем потокам и имеет большой объём. Константная и текстурная память кэшируются и эффективны при определённых шаблонах доступа.

---

### 2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?

Разделяемая память позволяет ускорить выполнение программы, когда данные используются несколькими потоками одного блока или к одним и тем же данным происходит многократное обращение. В таких случаях перенос данных из глобальной памяти в разделяемую уменьшает количество медленных обращений к глобальной памяти и снижает общую задержку выполнения.

---

### 3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?

Производительность GPU-программы существенно зависит от того, являются ли обращения к глобальной памяти коалесцированными. При коалесцированном доступе потоки одного варпа обращаются к соседним адресам памяти, что позволяет объединять запросы в меньшее число транзакций. Некоалесцированный доступ приводит к увеличению числа обращений к памяти и снижению производительности.

---

### 4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?

Даже при одинаковом алгоритме время выполнения может различаться из-за разной латентности доступа к памяти, количества транзакций к глобальной памяти и эффективности использования кешей. Неоптимальный доступ к памяти может приводить к простоям вычислительных блоков GPU, несмотря на одинаковый объём вычислений.

---

### 5. Как размер блока потоков влияет на производительность CUDA-ядра?

Размер блока потоков влияет на количество активных варпов на мультипроцессоре и на степень загрузки GPU. Слишком маленькие блоки приводят к недостаточному параллелизму, а слишком большие могут ограничивать использование регистров и разделяемой памяти. Оптимальный размер блока позволяет эффективно скрывать задержки доступа к памяти.

---

### 6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?

Варп — это группа из 32 потоков, которые выполняются одновременно по одной инструкции. Если потоки внутри варпа идут по разным ветвям исполнения, возникает расхождение потоков, что снижает производительность. Поэтому при разработке CUDA-программ важно минимизировать условные переходы внутри варпа.

---

### 7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?

При выборе конфигурации сетки и блоков необходимо учитывать размер задачи, архитектуру GPU, ограничения по количеству регистров и объёму разделяемой памяти, а также характер доступа к памяти. Целью является достижение высокой загрузки вычислительных блоков и эффективного скрытия задержек памяти.
