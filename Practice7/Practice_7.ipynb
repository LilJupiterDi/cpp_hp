{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nw2t08bqtr8O",
    "outputId": "42b18e1a-12cd-48a3-b17f-64b6f812d5d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reduction_kernel.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile reduction_kernel.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "#include <chrono>\n",
    "\n",
    "#define THREADS 256\n",
    "\n",
    "// ======================\n",
    "// Reduction kernel with shared memory\n",
    "// ======================\n",
    "__global__ void reduce_sum(const float* input, float* output, int N) {\n",
    "    __shared__ float sdata[THREADS];\n",
    "\n",
    "    int tid = threadIdx.x;\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // Load element into shared memory\n",
    "    sdata[tid] = (idx < N) ? input[idx] : 0.0f;\n",
    "    __syncthreads();\n",
    "\n",
    "    // Reduction in shared memory\n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (tid < s) sdata[tid] += sdata[tid + s];\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    // Write result of this block\n",
    "    if (tid == 0) output[blockIdx.x] = sdata[0];\n",
    "}\n",
    "\n",
    "// ======================\n",
    "// Host code\n",
    "// ======================\n",
    "int main() {\n",
    "    const int N = 1 << 20; // 1M elements\n",
    "    std::vector<float> h_input(N, 1.0f);\n",
    "    int blocks = (N + THREADS - 1) / THREADS;\n",
    "\n",
    "    float *d_input, *d_output;\n",
    "    cudaMalloc(&d_input, N * sizeof(float));\n",
    "    cudaMalloc(&d_output, blocks * sizeof(float));\n",
    "\n",
    "    cudaMemcpy(d_input, h_input.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "    auto start = std::chrono::high_resolution_clock::now();\n",
    "    reduce_sum<<<blocks, THREADS>>>(d_input, d_output, N);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // Final reduction on CPU\n",
    "    std::vector<float> h_partial(blocks);\n",
    "    cudaMemcpy(h_partial.data(), d_output, blocks * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    float sum = 0.0f;\n",
    "    for (auto v : h_partial) sum += v;\n",
    "\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "    std::cout << \"CUDA Reduction Sum: \" << sum << \"\\n\";\n",
    "    std::cout << \"Time: \" << std::chrono::duration<double, std::milli>(end - start).count() << \" ms\\n\";\n",
    "\n",
    "    // CPU sum for comparison\n",
    "    auto cpu_start = std::chrono::high_resolution_clock::now();\n",
    "    float cpu_sum = 0.0f;\n",
    "    for (auto v : h_input) cpu_sum += v;\n",
    "    auto cpu_end = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "    std::cout << \"CPU Sum: \" << cpu_sum << \"\\n\";\n",
    "    std::cout << \"CPU Time: \" << std::chrono::duration<double, std::milli>(cpu_end - cpu_start).count() << \" ms\\n\";\n",
    "\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cITS9U0tvs6",
    "outputId": "36392427-d80d-4ab3-f8f1-138e530cdc4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scan_kernel.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile scan_kernel.cu\n",
    "#include <cuda_runtime.h>\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "#include <chrono>\n",
    "\n",
    "#define THREADS 256\n",
    "\n",
    "// ======================\n",
    "// Prefix sum (exclusive scan) with shared memory\n",
    "// ======================\n",
    "__global__ void scan_kernel(float* data, int N) {\n",
    "    __shared__ float temp[THREADS];\n",
    "    int tid = threadIdx.x;\n",
    "    int idx = blockIdx.x * blockDim.x + tid;\n",
    "\n",
    "    // Load data into shared memory\n",
    "    temp[tid] = (idx < N) ? data[idx] : 0.0f;\n",
    "    __syncthreads();\n",
    "\n",
    "    // Up-sweep / reduce phase\n",
    "    for (int offset = 1; offset < blockDim.x; offset *= 2) {\n",
    "        int ai = (tid + 1) * offset * 2 - 1;\n",
    "        int bi = ai - offset;\n",
    "        if (ai < THREADS) temp[ai] += temp[bi];\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    // Clear last element for exclusive scan\n",
    "    if (tid == 0) temp[THREADS - 1] = 0;\n",
    "    __syncthreads();\n",
    "\n",
    "    // Down-sweep phase\n",
    "    for (int offset = THREADS / 2; offset > 0; offset /= 2) {\n",
    "        int ai = (tid + 1) * offset * 2 - 1;\n",
    "        int bi = ai - offset;\n",
    "        if (ai < THREADS) {\n",
    "            float t = temp[bi];\n",
    "            temp[bi] = temp[ai];\n",
    "            temp[ai] += t;\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    // Write results back\n",
    "    if (idx < N) data[idx] = temp[tid];\n",
    "}\n",
    "\n",
    "// ======================\n",
    "// Host code\n",
    "// ======================\n",
    "int main() {\n",
    "    const int N = 1 << 16; // smaller array for scan\n",
    "    std::vector<float> h_data(N, 1.0f);\n",
    "\n",
    "    float* d_data;\n",
    "    cudaMalloc(&d_data, N * sizeof(float));\n",
    "    cudaMemcpy(d_data, h_data.data(), N * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "    auto start = std::chrono::high_resolution_clock::now();\n",
    "    scan_kernel<<<(N + THREADS - 1)/THREADS, THREADS>>>(d_data, N);\n",
    "    cudaDeviceSynchronize();\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "    cudaMemcpy(h_data.data(), d_data, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Check correctness (sum of last element + 1 should equal total sum)\n",
    "    float total = 0.0f;\n",
    "    for (int i = 0; i < N; i++) total += 1.0f; // CPU sum for reference\n",
    "    std::cout << \"Last element after scan: \" << h_data[N-1] << \"\\n\";\n",
    "    std::cout << \"Total sum (CPU): \" << total << \"\\n\";\n",
    "    std::cout << \"CUDA Scan Time: \" << std::chrono::duration<double, std::milli>(end - start).count() << \" ms\\n\";\n",
    "\n",
    "    cudaFree(d_data);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMi8QGOgtv8M",
    "outputId": "0838f014-8a4f-4f10-a4cf-49b9dcb2ad46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Reduction Sum: 0\n",
      "Time: 42.9607 ms\n",
      "CPU Sum: 1.04858e+06\n",
      "CPU Time: 11.673 ms\n"
     ]
    }
   ],
   "source": [
    "!nvcc reduction_kernel.cu -o reduction\n",
    "!./reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zeWNf8umtzWF",
    "outputId": "1520e538-4c73-4d57-9d95-e56453d0ba0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last element after scan: 1\n",
      "Total sum (CPU): 65536\n",
      "CUDA Scan Time: 8.79022 ms\n"
     ]
    }
   ],
   "source": [
    "!nvcc scan_kernel.cu -o scan\n",
    "!./scan"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
