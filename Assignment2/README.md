# Assignment 2

### 1. Что понимается под гетерогенной параллелизацией?

**Гетерогенная параллелизация** — это организация вычислений с использованием **разнородных вычислительных устройств** (CPU, GPU и др.) в рамках одной задачи. Каждое устройство выполняет те части алгоритма, для которых оно архитектурно наиболее эффективно: CPU — управление и сложную логику, GPU — массовые параллельные вычисления.

---

### 2. В чём принципиальные различия архитектур CPU и GPU?

**CPU:**

* Небольшое число универсальных, мощных ядер.
* Большие кэши и сложная система управления потоками.
* Высокая производительность на последовательных задачах и при ветвлениях.
* Оптимизирован для низкой задержки.

**GPU:**

* Тысячи простых вычислительных ядер.
* Архитектура SIMD/SIMT.
* Небольшой кэш, высокая пропускная способность памяти.
* Оптимизирован для высокой пропускной способности (throughput), а не низкой задержки.

---

### 3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?

**Лучше подходят для GPU:**

* Массовые однотипные операции над большими массивами данных.
* Линейная алгебра (матрицы, векторы).
* Обработка изображений и видео.
* Обучение нейронных сетей.
* Физические и численные симуляции.

**Лучше подходят для CPU:**

* Задачи со сложной логикой и большим количеством ветвлений.
* Последовательные алгоритмы.
* Управление потоками и ввод-вывод.
* Задачи с нерегулярным доступом к памяти.

---

### 4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?

* **Последовательные зависимости** между шагами алгоритма.
* **Неравномерная нагрузка** между потоками.
* **Накладные расходы** на создание и синхронизацию потоков.
* **Критические секции** и блокировки, снижающие параллелизм.
* Ограничение по закону Амдала: последовательная часть ограничивает ускорение.

---

### 5. В чём заключается основная идея алгоритма сортировки слиянием?

Алгоритм **сортировки слиянием (Merge Sort)** основан на принципе *«разделяй и властвуй»*:

1. Массив рекурсивно разбивается на две части до подмассивов из одного элемента.
2. Отсортированные подмассивы последовательно **сливаются** в один отсортированный массив.

Алгоритм имеет сложность **O(n log n)** и является **стабильным**.

---

### 6. Какие сложности возникают при реализации сортировки слиянием на GPU?

* Сложная **рекурсивная структура**, плохо подходящая для GPU.
* **Нерегулярный доступ к памяти** при слиянии.
* Необходимость эффективной синхронизации потоков.
* Использование дополнительной памяти.
* Потери производительности из-за ветвлений и дивергенции потоков.

---

### 7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?

* **Слишком маленькие блоки** → плохая загрузка GPU.
* **Слишком большие блоки** → превышение ресурсов (регистры, shared memory).
* Оптимальный размер блока (часто 128–1024 потоков) обеспечивает:

  * максимальную занятость (occupancy),
  * скрытие задержек доступа к памяти,
  * эффективное использование shared memory.

Размер сетки определяет общее количество потоков и должен покрывать все данные.

---

### 8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?

* CPU и GPU компенсируют недостатки друг друга.
* CPU эффективно управляет логикой и последовательными частями.
* GPU ускоряет вычислительно интенсивные параллельные части.
* Снижаются накладные расходы и время выполнения.
* Повышается общая производительность и энергоэффективность.
